{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOs0yIUNUjIcwsxKGOFfwah",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/machiwao/CCDEPLRL_PROJECT_COM222/blob/blix/CCDEPLRL_PROJECT_COM222_Project_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ArtDecode: An Explainable Deep Learning-Based Mobile Application for Multi-Style Artistic Image Classification and Visual Feature Interpretation"
      ],
      "metadata": {
        "id": "kuvgqeBAYVhd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0pF1xCqXWORo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from PIL import Image  # PIL is used to load the image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "h00ztueYaBUW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive Data"
      ],
      "metadata": {
        "id": "Zx7EiEVvMSJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGShkGE0aAq1",
        "outputId": "5bdc85b1-6a11-45d5-9abb-be2882bdd010"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load images and respective labels"
      ],
      "metadata": {
        "id": "brk5TtLiMXsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/My Drive/Primary Data' # Adjust this path if \"Primary Data\" is in a different location"
      ],
      "metadata": {
        "id": "X3-3LGWeaZ9_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "styles = os.listdir(base_dir)\n",
        "print(styles) # Print the list of styles to verify"
      ],
      "metadata": {
        "id": "5hSeqFiPcUnf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36a0e906-77c3-4a50-f2bf-a75ce598cdf6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Primitivism', 'Art_Nouveau', 'Realism', 'Neoclassicism', 'Baroque', 'Japanese_Art', 'Academic_Art', 'Renaissance', 'Rococo', 'Expressionism', 'Romanticism', 'Symbolism', 'Western Medieval']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "labels = []\n",
        "for style in styles:\n",
        "    style_dir = os.path.join(base_dir, style)\n",
        "    for image_name in os.listdir(style_dir):\n",
        "        image_path = os.path.join(style_dir, image_name)\n",
        "        try:\n",
        "            img = Image.open(image_path).convert('RGB') # Load image and convert to RGB\n",
        "            img = img.resize((128, 128)) # Resize images to a consistent size\n",
        "            img_array = np.array(img)\n",
        "            images.append(img_array)\n",
        "            labels.append(style) # Use the style name as the label\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {image_path}: {e}\")\n",
        "\n",
        "images = np.array(images)"
      ],
      "metadata": {
        "id": "f327oDK7ceRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d07a4bb4-17e4-49a3-9912-35c7512e995a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1043: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3442: DecompressionBombWarning: Image size (96714256 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Split"
      ],
      "metadata": {
        "id": "2J3VVLRYc5s4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Validation-Test Split is 70-10-20\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.66, random_state=42)"
      ],
      "metadata": {
        "id": "XENrLiZ0c65K"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert y_train to a NumPy array to use NumPy functions\n",
        "y_train_np = np.array(y_train)\n",
        "\n",
        "# Get unique values and their counts\n",
        "unique_elements, counts = np.unique(y_train_np, return_counts=True)\n",
        "\n",
        "# Print the counts\n",
        "print(\"Counts of each style in y_train:\")\n",
        "for element, count in zip(unique_elements, counts):\n",
        "    print(f\"{element}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6k4CdYJh25Y",
        "outputId": "fbef1ac4-0d06-46ad-f90c-86c999c8158d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counts of each style in y_train:\n",
            "Academic_Art: 704\n",
            "Art_Nouveau: 697\n",
            "Baroque: 697\n",
            "Expressionism: 701\n",
            "Japanese_Art: 688\n",
            "Neoclassicism: 687\n",
            "Primitivism: 707\n",
            "Realism: 688\n",
            "Renaissance: 703\n",
            "Rococo: 682\n",
            "Romanticism: 697\n",
            "Symbolism: 731\n",
            "Western Medieval: 718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert y_val to a NumPy array to use NumPy functions\n",
        "y_val_np = np.array(y_val)\n",
        "\n",
        "# Get unique values and their counts\n",
        "unique_elements, counts = np.unique(y_val_np, return_counts=True)\n",
        "\n",
        "# Print the counts\n",
        "print(\"Counts of each style in y_val:\")\n",
        "for element, count in zip(unique_elements, counts):\n",
        "    print(f\"{element}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T-yMlFViDQi",
        "outputId": "c579f820-c8de-45ed-cd0e-bf14bb12870f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counts of each style in y_val:\n",
            "Academic_Art: 113\n",
            "Art_Nouveau: 111\n",
            "Baroque: 98\n",
            "Expressionism: 102\n",
            "Japanese_Art: 88\n",
            "Neoclassicism: 119\n",
            "Primitivism: 93\n",
            "Realism: 105\n",
            "Renaissance: 102\n",
            "Rococo: 110\n",
            "Romanticism: 115\n",
            "Symbolism: 96\n",
            "Western Medieval: 74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_to_index = {style: i for i, style in enumerate(styles)}\n",
        "y_train_encoded = to_categorical([label_to_index[label] for label in y_train], num_classes=len(styles))\n",
        "y_val_encoded = to_categorical([label_to_index[label] for label in y_val], num_classes=len(styles))\n",
        "y_test_encoded = to_categorical([label_to_index[label] for label in y_test], num_classes=len(styles))\n",
        "\n",
        "# Normalize the image data after splitting\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_val = X_val.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "u5pyyURYi06z"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "418pOQ_Wcwp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, 3, activation=\"relu\", input_shape=(128, 128, 3)), # Add input_shape here\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, 3, activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    tf.keras.layers.Conv2D(256, 3, activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(len(styles))  # Output layer with number of classes\n",
        "])"
      ],
      "metadata": {
        "id": "NKJTwPd_cwew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e45556cf-6cb9-44f7-90b4-596d273d3fa8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "2g8-Gy5aeCC4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "5004ff41-1ec9-4620-d780-442917807d04"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50176\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m12,845,312\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)             │         \u001b[38;5;34m3,341\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,845,312</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,341</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,219,469\u001b[0m (50.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,219,469</span> (50.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,219,469\u001b[0m (50.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,219,469</span> (50.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize starting learning rate\n",
        "initial_learning_rate = 0.0001\n",
        "# Initialize optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate)\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    # Change the loss function to CategoricalCrossentropy for one-hot encoded labels\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing = 0.1),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "g5xGO8rbd__o"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience = 20,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1,\n",
        "    min_delta=0.0001,\n",
        ")"
      ],
      "metadata": {
        "id": "PX9pIHEVeCRA"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,        # Reduce LR by half\n",
        "    patience=10,        # Wait 3 epochs before reducing\n",
        "    min_lr=1e-7,       # Don't go below this\n",
        "    min_delta=0.0001,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "BNvNHShNeIbw"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history = model.fit(\n",
        "    X_train, y_train_encoded, # Use the one-hot encoded training labels\n",
        "    epochs=100,\n",
        "    validation_data=(X_val, y_val_encoded), # Use the one-hot encoded validation labels\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "id": "FBqtAUT9eSfE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "794b83ca-2b0f-4fba-c616-3dfa24acb513"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 52ms/step - accuracy: 0.1356 - loss: 2.4863 - val_accuracy: 0.2036 - val_loss: 2.3526 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 38ms/step - accuracy: 0.2919 - loss: 2.1466 - val_accuracy: 0.3137 - val_loss: 2.1013 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.3508 - loss: 1.9723 - val_accuracy: 0.3341 - val_loss: 2.0402 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.4147 - loss: 1.8120 - val_accuracy: 0.3718 - val_loss: 1.9521 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.4488 - loss: 1.6927 - val_accuracy: 0.3620 - val_loss: 1.9570 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.4924 - loss: 1.5527 - val_accuracy: 0.3763 - val_loss: 1.8838 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.5223 - loss: 1.4483 - val_accuracy: 0.3824 - val_loss: 1.9374 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.5938 - loss: 1.2521 - val_accuracy: 0.3808 - val_loss: 1.9386 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.6484 - loss: 1.1013 - val_accuracy: 0.3763 - val_loss: 2.0196 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.6915 - loss: 0.9666 - val_accuracy: 0.3959 - val_loss: 2.0200 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.7470 - loss: 0.8111 - val_accuracy: 0.4035 - val_loss: 2.0861 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.7870 - loss: 0.6824 - val_accuracy: 0.4012 - val_loss: 2.1393 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.8338 - loss: 0.5593 - val_accuracy: 0.3944 - val_loss: 2.3293 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.8519 - loss: 0.4809 - val_accuracy: 0.3831 - val_loss: 2.4688 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.8873 - loss: 0.3877 - val_accuracy: 0.3891 - val_loss: 2.5358 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m284/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9070 - loss: 0.3119\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.9070 - loss: 0.3120 - val_accuracy: 0.3846 - val_loss: 2.7711 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.9477 - loss: 0.2183 - val_accuracy: 0.3899 - val_loss: 2.8401 - learning_rate: 5.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.9470 - loss: 0.1925 - val_accuracy: 0.3884 - val_loss: 2.8378 - learning_rate: 5.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.9582 - loss: 0.1610 - val_accuracy: 0.3982 - val_loss: 2.9870 - learning_rate: 5.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.9654 - loss: 0.1432 - val_accuracy: 0.3884 - val_loss: 3.0822 - learning_rate: 5.0000e-05\n",
            "Epoch 21/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.9681 - loss: 0.1331 - val_accuracy: 0.3763 - val_loss: 3.0937 - learning_rate: 5.0000e-05\n",
            "Epoch 22/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.9694 - loss: 0.1202 - val_accuracy: 0.3922 - val_loss: 3.1108 - learning_rate: 5.0000e-05\n",
            "Epoch 23/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.9763 - loss: 0.1032 - val_accuracy: 0.3816 - val_loss: 3.2347 - learning_rate: 5.0000e-05\n",
            "Epoch 24/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.9755 - loss: 0.1029 - val_accuracy: 0.3695 - val_loss: 3.3418 - learning_rate: 5.0000e-05\n",
            "Epoch 25/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.9814 - loss: 0.0834 - val_accuracy: 0.3808 - val_loss: 3.4134 - learning_rate: 5.0000e-05\n",
            "Epoch 26/100\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9804 - loss: 0.0835\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.9804 - loss: 0.0835 - val_accuracy: 0.3959 - val_loss: 3.4529 - learning_rate: 5.0000e-05\n",
            "Epoch 26: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "0-Qkz2THc1lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history):\n",
        "  fig, (ax1, ax2) = plt.subplots(2, figsize=(12, 12))\n",
        "  ax1.plot(history.history['accuracy'])\n",
        "  ax1.plot(history.history['val_accuracy'])\n",
        "  ax1.set_title('model accuracy')\n",
        "  ax1.set_ylabel('accuracy')\n",
        "  ax1.set_xlabel('epoch')\n",
        "  ax1.legend(['train', 'validation'], loc='upper left')\n",
        "  ax2.plot(history.history['loss'])\n",
        "  ax2.plot(history.history['val_loss'])\n",
        "  ax2.set_title('model loss')\n",
        "  ax2.set_ylabel('loss')\n",
        "  ax2.set_xlabel('epoch')"
      ],
      "metadata": {
        "id": "Ml02STOcc2kt"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Pfy6v_9NF5F",
        "outputId": "50f7c115-3419-4e3b-fb37-c2ba238c3a50"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4329 - loss: 1.8061\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.8297455310821533, 0.4176379144191742]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Classification Report. Print which number represents which art style\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "print(classification_report(y_test_classes, y_pred_classes, target_names=styles))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBOo-PzdNIfv",
        "outputId": "08654d98-a7cb-4095-a767-c4dff867354d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "     Primitivism       0.46      0.38      0.41       200\n",
            "     Art_Nouveau       0.54      0.47      0.50       192\n",
            "         Realism       0.36      0.37      0.37       207\n",
            "   Neoclassicism       0.58      0.57      0.58       194\n",
            "         Baroque       0.40      0.29      0.34       205\n",
            "    Japanese_Art       0.72      0.65      0.69       224\n",
            "    Academic_Art       0.43      0.46      0.45       183\n",
            "     Renaissance       0.32      0.31      0.32       195\n",
            "          Rococo       0.53      0.40      0.46       208\n",
            "   Expressionism       0.23      0.48      0.31       197\n",
            "     Romanticism       0.36      0.34      0.35       188\n",
            "       Symbolism       0.20      0.22      0.21       173\n",
            "Western Medieval       0.54      0.44      0.48       208\n",
            "\n",
            "        accuracy                           0.42      2574\n",
            "       macro avg       0.44      0.41      0.42      2574\n",
            "    weighted avg       0.44      0.42      0.42      2574\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print which number represents which art style\n",
        "label_to_index = {style: i for i, style in enumerate(styles)}\n",
        "index_to_label = {i: style for style, i in label_to_index.items()}\n",
        "print(index_to_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIMQSeFJhS0H",
        "outputId": "ed944dec-ad87-4e28-8beb-ac7be77df2c6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'Primitivism', 1: 'Art_Nouveau', 2: 'Realism', 3: 'Neoclassicism', 4: 'Baroque', 5: 'Japanese_Art', 6: 'Academic_Art', 7: 'Renaissance', 8: 'Rococo', 9: 'Expressionism', 10: 'Romanticism', 11: 'Symbolism', 12: 'Western Medieval'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZMNan_JKlRdt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}